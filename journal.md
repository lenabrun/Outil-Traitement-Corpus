## TP 1
### Partie 1 | Étude de cas CoNLL 2003
**Quel type de tâche propose CoNLL 2003 ?**  
⇒ CoNLL 2003 propose la tâche de reconnaissance d’entités nommées, en particulier les personnes, les lieux, les organisations et les autres entités qui ne font pas parties des trois catégories précédentes.  

**Quel type de données y a-t-il dans CoNLL 2003 ?**  
⇒ Les données du CoNLL 2003 se présentent en 4 colonnes, chacune séparée par un simple espace. La première colonne contient un mot, la deuxième son étiquette de partie du discours POS, la troisième son étiquette de groupe syntaxique (GN, GV…), et la quatrième son type d’entité nommée.  

**À quel besoin répond CoNLL 2003 ?**  
⇒ CoNLL 2003 propose un corpus annoté pour des modèles qui cherchent à faire de la reconnaissance d’entités nommées.  

**Quels types de modèles ont été entraînés sur CoNLL 2003 ?**  
⇒ Des modèles de reconnaissances d’entités nommées (NER) comme bert-base-NER et des modèles utilisant Flair ont été entrainés sur le CoNLL 2003.  

**Est-ce un corpus monolingue ou multilingue ?**  
⇒ CoNLL 2003 est un corpus multilingue qui a permis à des modèles de s’entraîner dessus pour plusieurs langues comme l’anglais, l’allemand et le français.  
#
### Partie 2 | Projet   
**Dans quel besoin vous inscrivez-vous ?**  
⇒ Le besoin est d'automatiser l'extraction d'informations structurées à partir d'articles scientifiques, afin de faciliter la recherche, l'indexation et l'analyse de contenus spécialisés. Cela répond à une problématique de surcharge informationnelle dans le domaine scientifique, où la quantité de publications rend difficile la veille et la synthèse manuelle.  

**Quel sujet allez-vous traiter ?**  
⇒ L'extraction d'entités nommées (NER) dans des articles scientifiques en français, avec un accent particulier sur les entités spécifiques au domaine, telles que les noms de maladies, de composés chimiques, d'organismes de recherche, etc.  

**Quel type de tâche allez-vous réaliser ?**  
⇒  Une tâche de reconnaissance d'entités nommées (NER), qui est une tâche supervisée de traitement automatique du langage.  

**Quel type de données allez-vous exploiter ?**  
⇒ Des textes scientifiques en français, extraits d'articles académiques au format .txt, nettoyés et prétraités pour l'analyse linguistique.  

**Où allez vous récupérer vos données ?**  
⇒ Les données proviennent de la section Santé de The Conversation France, une plateforme en ligne qui publie des articles rédigés par des chercheurs et des universitaires, offrant des analyses approfondies sur divers sujets d'actualité dans le domaine des sciences et de la santé.  

**Sont-elles libres d'accès ?**  
⇒ Oui, les articles de The Conversation sont publiés sous la licence Creative Commons CC-BY-ND, ce qui permet leur réutilisation sans modification, à condition de citer correctement la source.  
   
## TP 2
### Récupération du corpus

## TP 3
### Visualisation des statistiques

